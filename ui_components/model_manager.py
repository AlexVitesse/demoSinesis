# Importaci√≥n de bibliotecas y m√≥dulos necesarios:
# - streamlit: Framework para crear interfaces web interactivas
# - vector_store: M√≥dulo personalizado para gesti√≥n de almacenes vectoriales
import streamlit as st
from vector_store import VectorStoreManager


@st.cache_resource  # Decorador de Streamlit para cachear recursos costosos
def load_embedding_model():
    """Funci√≥n cacheada para cargar el modelo una sola vez
    
    Prop√≥sito:
        - Cargar el modelo de embeddings de manera eficiente
        - Evitar recargas innecesarias durante la sesi√≥n
        - Proporcionar feedback visual durante la carga
        
    Caracter√≠sticas:
        - Cacheada a nivel de recurso (persiste entre reruns)
        - Muestra spinner durante la carga
        - Maneja errores adecuadamente
        
    Returns:
        Modelo de embeddings cargado o None en caso de error
        
    Notas:
        - Usa el modelo 'all-MiniLM-L6-v2' de Sentence Transformers
        - La cach√© se mantiene mientras la app est√© en ejecuci√≥n
    """
    vs_manager = VectorStoreManager()  # Instancia del gestor de almac√©n vectorial
    model_name = "sentence-transformers/all-MiniLM-L6-v2"  # Modelo pre-entrenado de HuggingFace
    
    try:
        # Bloque de carga con feedback visual
        with st.spinner(f"üîç Cargando modelo all-MiniLM-L6-v2 (solo una vez)..."):
            # Configura el modelo de embeddings a trav√©s del VectorStoreManager
            embed_model = vs_manager.setup_embeddings(model_name)
            print(f"Modelo {model_name} cargado correctamente")  # Log para depuraci√≥n
            return embed_model
    except Exception as e:
        # Manejo de errores con mensaje claro en UI
        st.error(f"‚ùå Error al cargar el modelo: {e}")
        return None  # Retorno expl√≠cito para manejo de fallos


class ModelManager:
    """Maneja la carga y gesti√≥n del modelo de embeddings
    
    Responsabilidades:
        - Gesti√≥n centralizada del modelo de embeddings
        - Control del estado de carga del modelo
        - Proporcionar interfaz uniforme para acceder al modelo
        
    Atributos:
        - embed_model: Referencia al modelo cargado (None si no est√° cargado)
        - model_name: Nombre del modelo predefinido
        
    Patrones:
        - Singleton impl√≠cito (una instancia por app)
        - Lazy initialization (carga bajo demanda)
    """
    
    def __init__(self):
        """Inicializa el gestor de modelos
        
        Estado inicial:
            - Modelo no cargado (None)
            - Nombre del modelo predefinido
        """
        self.embed_model = None  # Modelo de embeddings (inicialmente no cargado)
        self.model_name = "sentence-transformers/all-MiniLM-L6-v2"  # Modelo por defecto
    
    def initialize_model(self):
        """Inicializa el modelo de embeddings
        
        Flujo:
            1. Llama a la funci√≥n cacheada load_embedding_model()
            2. Almacena el modelo cargado en el atributo de instancia
            
        Returns:
            Modelo cargado o None si fall√≥ la carga
            
        Notas:
            - Aprovecha el caching de Streamlit para optimizaci√≥n
            - Solo realiza la carga real la primera vez
        """
        self.embed_model = load_embedding_model()  # Delegar la carga a la funci√≥n cacheada
        return self.embed_model
    
    def get_model(self):
        """Obtiene el modelo actual
        
        Returns:
            Modelo de embeddings cargado o None
            
        Uso t√≠pico:
            - Para acceder al modelo en otras partes de la aplicaci√≥n
            - Verificar disponibilidad antes de usarlo
            
        Consideraciones:
            - Puede devolver None si el modelo no se carg√≥ correctamente
            - Los llamantes deben verificar el retorno
        """
        return self.embed_model
    
    def is_model_loaded(self) -> bool:
        """Verifica si el modelo est√° cargado
        
        Returns:
            bool: True si el modelo est√° cargado, False en caso contrario
            
        Prop√≥sito:
            - Permitir verificaciones r√°pidas de estado
            - Evitar intentar usar el modelo cuando no est√° disponible
            
        Ejemplo de uso:
            if model_manager.is_model_loaded():
                # Operaciones seguras con el modelo
        """
        return self.embed_model is not None  # Expresi√≥n booleana expl√≠cita
    
    def get_model_name(self) -> str:
        """Obtiene el nombre del modelo
        
        Returns:
            str: Nombre del modelo configurado
            
        Prop√≥sito:
            - Mostrar informaci√≥n del modelo en UI
            - Prop√≥sitos de logging y depuraci√≥n
            - Consistencia en referencias al modelo
            
        Notas:
            - Siempre retorna el nombre, independientemente del estado de carga
        """
        return self.model_name